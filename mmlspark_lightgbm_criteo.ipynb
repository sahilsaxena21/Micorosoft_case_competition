{"cells":[{"cell_type":"markdown","source":["<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n\n<i>Licensed under the MIT License.</i>"],"metadata":{}},{"cell_type":"markdown","source":["# Content-Based Personalization with LightGBM on Spark\n\nThis notebook provides a quick example of how to train a [LightGBM](https://github.com/Microsoft/Lightgbm) model on Spark using [MMLSpark](https://github.com/Azure/mmlspark) for a content-based personalization scenario.\n\nWe use the [CRITEO dataset](https://www.kaggle.com/c/criteo-display-ad-challenge), a well known dataset of website ads that can be used to optimize the Click-Through Rate (CTR). The dataset consists of a series of numerical and categorical features and a binary label indicating whether the add has been clicked or not.\n\nThe model is based on [LightGBM](https://github.com/Microsoft/Lightgbm), which is a gradient boosting framework that uses tree-based learning algorithms. Finally, we take advantage of\n[MMLSpark](https://github.com/Azure/mmlspark) library, which allows LightGBM to be called in a Spark environment and be computed distributely.\n\nThis scenario is a good example of **implicit feedback**, where binary labels indicate the interaction between a user and an item. This contrasts with explicit feedback, where the user explicitely rate the content, for example from 1 to 5."],"metadata":{}},{"cell_type":"markdown","source":["## Global Settings and Imports"],"metadata":{}},{"cell_type":"markdown","source":["This notebook can be run in a Spark environment in a DSVM or in Azure Databricks. For more details about the installation process, please refer to the [setup instructions](../../SETUP.md).\n\n**NOTE for Azure Databricks:**\n* A python script is provided to simplify setting up Azure Databricks with the correct dependencies. Run ```python scripts/databricks_install.py -h``` for more details.\n* MMLSpark should not be run on a cluster with autoscaling enabled. Disable the flag in the Azure Databricks Cluster configuration before running this notebook."],"metadata":{}},{"cell_type":"code","source":["!pip install tqdm\n!pip install papermill\nfrom azureml.core import Workspace\n\nsubscription_id = '796515a0-d9b7-4ab5-9507-440d24feca8e'\nresource_group  = 'azure_competition'\nworkspace_name  = 'workspace_ml'\n\ntry:\n    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n    ws.write_config()\n    print('Library configuration succeeded')\nexcept:\n    print('Workspace not found')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Library configuration succeeded\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["import os\nimport sys\n\nsys.path.append(\"../../\")\n\nimport pyspark\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.feature import FeatureHasher\nimport papermill as pm\n\nfrom reco_utils.common.spark_utils import start_or_get_spark\nfrom reco_utils.common.notebook_utils import is_databricks\nfrom reco_utils.dataset.criteo import load_spark_df\nfrom reco_utils.dataset.spark_splitters import spark_random_split\n\n# Setup MML Spark\nif not is_databricks():\n    # get the maven coordinates for MML Spark from databricks_install script\n    from scripts.databricks_install import MMLSPARK_INFO\n    packages = [MMLSPARK_INFO[\"maven\"][\"coordinates\"]]\n    repo = MMLSPARK_INFO[\"maven\"].get(\"repo\")\n    spark = start_or_get_spark(packages=packages, repository=repo)\n    dbutils = None\n    print(\"MMLSpark version: {}\".format(MMLSPARK_INFO['maven']['coordinates']))\n\nfrom mmlspark.train import ComputeModelStatistics\nfrom mmlspark.lightgbm import LightGBMClassifier\n\nprint(\"System version: {}\".format(sys.version))\nprint(\"PySpark version: {}\".format(pyspark.version.__version__))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">System version: 3.7.3 (default, Feb 20 2020, 02:03:03) \n[GCC 5.4.0 20160609]\nPySpark version: 2.4.6.dev0\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Criteo data size, it can be \"sample\" or \"full\"\nDATA_SIZE = \"sample\"\n\n# LightGBM parameters\n# More details on parameters: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\nNUM_LEAVES = 32\nNUM_ITERATIONS = 50\nLEARNING_RATE = 0.1\nFEATURE_FRACTION = 0.8\nEARLY_STOPPING_ROUND = 10\n\n# Model name\nMODEL_NAME = 'lightgbm_criteo.mml'"],"metadata":{"tags":["parameters"]},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["## Data Preparation\n\nThe [Criteo Display Advertising Challenge](https://www.kaggle.com/c/criteo-display-ad-challenge) (Criteo DAC) dataset is a well-known industry benchmarking dataset for developing CTR prediction models, and is used frequently by research papers. The original dataset contains over 45M rows, but there is also a down-sampled dataset which has 100,000 rows (this can be used by setting `DATA_SIZE = \"sample\"`). Each row corresponds to a display ad served by Criteo and the first column is indicates whether this ad has been clicked or not.<br><br>\nThe dataset contains 1 label column and 39 feature columns, where 13 columns are integer values (int00-int12) and 26 columns are categorical features (cat00-cat25).<br><br>\nWhat the columns represent is not provided, but for this case we can consider the integer and categorical values as features representing the user and / or item content. The label is binary and is an example of implicit feedback indicating a user's interaction with an item. With this dataset we can demonstrate how to build a model that predicts the probability of a user interacting with an item based on available user and item content features."],"metadata":{}},{"cell_type":"code","source":["# File location and type\nfile_location = \"/FileStore/tables/synth_data.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"false\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\nraw_data = spark.read.format(file_type) \\\n  .option(\"inferSchema\", \"true\") \\\n  .option(\"header\", \"true\") \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["raw_data.limit(2).toPandas().head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_c0</th>\n      <th>customer_ID</th>\n      <th>category</th>\n      <th>y</th>\n      <th>pur_value</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>17850.0</td>\n      <td>Video Game Accessories</td>\n      <td>1</td>\n      <td>255.0</td>\n      <td>Montreal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>17850.0</td>\n      <td>Other</td>\n      <td>1</td>\n      <td>339.0</td>\n      <td>Edmonton</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["raw_data.createOrReplaceTempView(\"synth_data\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# %sql\n\n# /* Query the created temp table in a SQL cell */\n\n# select CAST(customer_ID as int), CAST(category as string), CAST(y as int), CAST(pur_value as int), CAST(city as string)\n# from `synth_data`\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["# raw_data = load_spark_df(size=DATA_SIZE, spark=spark, dbutils=dbutils)\n# # visualize data\n# raw_data.limit(2).toPandas().head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["### Feature Processing\nThe feature data provided has many missing values across both integer and categorical feature fields. In addition the categorical features have many distinct values, so effectively cleaning and representing the feature data is an important step prior to training a model.<br><br>\nOne of the simplest ways of managing both features that have missing values as well as high cardinality is to use the hashing trick. The [FeatureHasher](http://spark.apache.org/docs/latest/ml-features.html#featurehasher) transformer will pass integer values through and will hash categorical features into a sparse vector of lower dimensionality, which can be used effectively by LightGBM.<br><br>\nFirst, the dataset is splitted randomly for training and testing and feature processing is applied to each dataset."],"metadata":{}},{"cell_type":"code","source":["raw_train, raw_test = spark_random_split(raw_data, ratio=0.8, seed=42)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["columns = [c for c in raw_data.columns if c != 'y']\nfeature_processor = FeatureHasher(inputCols=columns, outputCol='features')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["train = feature_processor.transform(raw_train)\ntest = feature_processor.transform(raw_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["## Model Training\nIn MMLSpark, the LightGBM implementation for binary classification is invoked using the `LightGBMClassifier` class and specifying the objective as `\"binary\"`. In this instance, the occurrence of positive labels is quite low, so setting the `isUnbalance` flag to true helps account for this imbalance.<br><br>\n\n### Hyper-parameters\nBelow are some of the key [hyper-parameters](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters-Tuning.rst) for training a LightGBM classifier on Spark:\n- `numLeaves`: the number of leaves in each tree\n- `numIterations`: the number of iterations to apply boosting\n- `learningRate`: the learning rate for training across trees\n- `featureFraction`: the fraction of features used for training a tree\n- `earlyStoppingRound`: round at which early stopping can be applied to avoid overfitting"],"metadata":{}},{"cell_type":"code","source":["lgbm = LightGBMClassifier(\n    labelCol=\"y\",\n    featuresCol=\"features\",\n    objective=\"multiclass\",\n    isUnbalance=True,\n    boostingType=\"gbdt\",\n    boostFromAverage=True,\n    baggingSeed=42,\n    numLeaves=NUM_LEAVES,\n    numIterations=NUM_ITERATIONS,\n    learningRate=LEARNING_RATE,\n    featureFraction=FEATURE_FRACTION,\n    earlyStoppingRound=EARLY_STOPPING_ROUND\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["### Model Training and Evaluation"],"metadata":{}},{"cell_type":"code","source":["model = lgbm.fit(train)\npredictions = model.transform(test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["evaluator = (\n    ComputeModelStatistics()\n    .setScoredLabelsCol(\"prediction\")\n    .setLabelCol(\"y\")\n    .setEvaluationMetric(\"classification\")\n)\n\nresult = evaluator.transform(predictions)\n# auc = result.select(\"confusion_matrix\").collect()[0][0]\nresult.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+--------------------+------------------+------------------+------------------+------------------+------------------------+---------------------+\nevaluation_type|    confusion_matrix|          accuracy|         precision|            recall|  average_accuracy|macro_averaged_precision|macro_averaged_recall|\n+---------------+--------------------+------------------+------------------+------------------+------------------+------------------------+---------------------+\n Classification|8153.0  1.0    31...|0.8309816121326593|0.8309816121326593|0.8309816121326593|0.9323926448530637|      0.8270688979196852|   0.4217247010379522|\n+---------------+--------------------+------------------+------------------+------------------+------------------+------------------------+---------------------+\n\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["# # Record results with papermill for tests\n# pm.record(\"auc\", auc)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["## Model Saving \nThe full pipeline for operating on raw data including feature processing and model prediction can be saved and reloaded for use in another workflow."],"metadata":{}},{"cell_type":"code","source":["# save model\npipeline = PipelineModel(stages=[feature_processor, model])\npipeline.write().overwrite().save(MODEL_NAME)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["# cleanup spark instance\nif not is_databricks():\n    spark.stop()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["## Additional Reading\n\\[1\\] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. LightGBM: A highly efficient gradient boosting decision tree. In Advances in Neural Information Processing Systems. 3146–3154. https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf <br>\n\\[2\\] MML Spark: https://mmlspark.blob.core.windows.net/website/index.html <br>"],"metadata":{}}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.8","nbconvert_exporter":"python","file_extension":".py"},"name":"mmlspark_lightgbm_criteo","notebookId":4378841618340966,"kernelspec":{"display_name":"Python (reco_pyspark)","language":"python","name":"reco_pyspark"},"celltoolbar":"Tags"},"nbformat":4,"nbformat_minor":0}
