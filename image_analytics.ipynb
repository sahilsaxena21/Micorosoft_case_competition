{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "name": "computervision",
    "notebookId": 259630694391314,
    "colab": {
      "name": "image_analytics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6muwKvqEM5GG",
        "colab_type": "text"
      },
      "source": [
        "#Install and load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S4S7SIfJl22",
        "colab_type": "code",
        "outputId": "4ec065d0-9806-40aa-e4ed-378d1f2bb878",
        "colab": {}
      },
      "source": [
        "!pip install azure.cognitiveservices.vision.computervision\n",
        "!pip install PIL\n",
        "!pip install Pillow\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTdFwiMkJl2_",
        "colab_type": "code",
        "outputId": "5f29bafd-84c1-4b78-80a1-76c0cbdf57a5",
        "colab": {}
      },
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import TextOperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import TextRecognitionMode\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl8xt2woJl3K",
        "colab_type": "code",
        "outputId": "82957485-ac65-4573-8dba-752ea3622127",
        "colab": {}
      },
      "source": [
        "subscription_key = '10f93b9fbccd48209981e11e3c672401'\n",
        "endpoint = 'https://compvisioncentralus.cognitiveservices.azure.com/'\n",
        "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
        "remote_image_url = \"https://raw.githubusercontent.com/sahilsaxena21/Microsoft_case_competition/master/img_1_jpeg.jpg\"\n",
        "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flteHwSzc92H",
        "colab_type": "text"
      },
      "source": [
        "It is assumed that the security surveillance system within each store is able record pictures and snapshots on a regular schedule. It is to be noted that in this example, the image is saved in a remote link. For a more feasible implementation, our team will have to look into building a pipeline to continuously feed the images recorded by the security surveillance system to Azure Blob storage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BDBZtZBJqAQ",
        "colab_type": "text"
      },
      "source": [
        "#Get Image Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paN4AEYfJl3o",
        "colab_type": "code",
        "outputId": "13d5b1b9-735e-4f47-e943-f1fe158c57b1",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Describe an Image - remote\n",
        "This example describes the contents of an image with the confidence score.\n",
        "'''\n",
        "print(\"===== Describe an image - remote =====\")\n",
        "# Call API\n",
        "description_results = computervision_client.describe_image(remote_image_url )\n",
        "\n",
        "# Get the captions (descriptions) from the response, with confidence level\n",
        "print(\"Description of remote image: \")\n",
        "if (len(description_results.captions) == 0):\n",
        "    print(\"No description detected.\")\n",
        "else:\n",
        "    for caption in description_results.captions:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\">===== Describe an image - remote =====\n",
              "Description of remote image: \n",
              "&#39;a group of people standing in front of a shop&#39; with confidence 70.87%\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msIIl_0EJwcs",
        "colab_type": "text"
      },
      "source": [
        "#Get Faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3iMzt4aJl3w",
        "colab_type": "code",
        "outputId": "f2455db7-ac37-4f63-df09-6ad48d9b03af",
        "colab": {}
      },
      "source": [
        "print(\"===== Detect Faces - remote =====\")\n",
        "# Get an image with faces\n",
        "remote_image_url_faces = \"https://raw.githubusercontent.com/sahilsaxena21/Microsoft_case_competition/master/img_1_jpeg.jpg\"\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"faces\"]\n",
        "# Call the API with remote URL and features\n",
        "detect_faces_results_remote = computervision_client.analyze_image(remote_image_url_faces, remote_image_features)\n",
        "\n",
        "# Print the results with gender, age, and bounding box\n",
        "print(\"Faces in the remote image: \")\n",
        "if (len(detect_faces_results_remote.faces) == 0):\n",
        "    print(\"No faces detected.\")\n",
        "else:\n",
        "    for face in detect_faces_results_remote.faces:\n",
        "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
        "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
        "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
        "        face.face_rectangle.top + face.face_rectangle.height))\n",
        "# </snippet_faces>\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\">===== Detect Faces - remote =====\n",
              "Faces in the remote image: \n",
              "No faces detected.\n",
              "\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jL_JyIJJ-jj",
        "colab_type": "text"
      },
      "source": [
        "We see that no faces are detected from the example image. Here, we wanted to acknowledge this possibility. In such cases, the gender and age data will be marked as N/A. For the purposes of illustration of the metadata generated from the image analysis, we fill in these values with synthetic data in the code block below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Oz8cr-TJzNt",
        "colab_type": "text"
      },
      "source": [
        "#Get location of people"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j8qTlWSLXMj",
        "colab_type": "text"
      },
      "source": [
        "We use the bounding box cordinates for each person to record the location of the person within the store. An example metadata generated from the image analytics is illustrated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p8fCP84Jl35",
        "colab_type": "code",
        "outputId": "ad0f6616-e1b7-4969-d303-2a07b98744dc",
        "colab": {}
      },
      "source": [
        "#use the bounding box of each person to get the count of people and their location within the store\n",
        "'''\n",
        "Detect Objects - remote\n",
        "This example detects different kinds of objects with bounding boxes in a remote image.\n",
        "'''\n",
        "\n",
        "person_count = 0\n",
        "person_loc_list = []\n",
        "person_gender_list = []\n",
        "person_age_list = []\n",
        "\n",
        "df = pd.DataFrame(columns = [\"Timestamp\", \"Age\", \"Gender\", \"location_category\", \"bestbuy_employee\"])\n",
        "\n",
        "print(\"===== Detect Objects - remote =====\")\n",
        "# Get URL image with different objects\n",
        "remote_image_url_objects = \"https://raw.githubusercontent.com/sahilsaxena21/Micorosoft_case_competition/master/img_1_jpeg.jpg\"\n",
        "# Call API with URL\n",
        "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
        "\n",
        "# Print detected objects results with bounding boxes\n",
        "print(\"Detecting objects in remote image:\")\n",
        "if len(detect_objects_results_remote.objects) == 0:\n",
        "    print(\"No objects detected.\")\n",
        "else:\n",
        "    for object in detect_objects_results_remote.objects:\n",
        "      #if the object is a person, get the bounding box location\n",
        "      if object.object_property == \"person\":\n",
        "        person_count = person_count + 1\n",
        "        if (object.rectangle.x < 55) and (object.rectangle.y > 80) and (object.rectangle.y < 120) :\n",
        "          person_location = \"cashier\"\n",
        "          person_loc_list.append(\"cashier\")\n",
        "\n",
        "          to_append = [\"04/03/2020 19:53:25\", 52, \"Female\", person_location, \"No\"]\n",
        "          df_length = len(df)\n",
        "          df.loc[df_length] = to_append\n",
        "          \n",
        "        elif object.rectangle.x > 590:\n",
        "          person_location = \"entrance\"\n",
        "          person_loc_list.append(\"entrance\")\n",
        "\n",
        "          to_append = [\"04/03/2020 19:53:25\", 32, \"Female\", person_location, \"No\"]\n",
        "          df_length = len(df)\n",
        "          df.loc[df_length] = to_append\n",
        "          \n",
        "        elif (object.rectangle.x > 190) and (object.rectangle.x < 210):\n",
        "          person_location = \"Isle_1\"\n",
        "          person_loc_list.append(\"Isle_1\")\n",
        "\n",
        "          to_append = [\"04/03/2020 19:53:25\", 22, \"Female\", person_location, \"No\"]\n",
        "          df_length = len(df)\n",
        "          df.loc[df_length] = to_append\n",
        "          \n",
        "        elif (object.rectangle.x > 440) and (object.rectangle.x < 460):\n",
        "          person_location = \"Isle_2\"\n",
        "          person_loc_list.append(\"Isle_2\")\n",
        "\n",
        "          to_append = [\"04/03/2020 19:53:25\", 41, \"Male\", person_location, \"No\"]\n",
        "          df_length = len(df)\n",
        "          df.loc[df_length] = to_append\n",
        "      \n",
        "      \n",
        "                    \n",
        "print(\"Total number of people in image = \", person_count)\n",
        "print(df)      \n",
        "          \n",
        "          "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\">===== Detect Objects - remote =====\n",
              "Detecting objects in remote image:\n",
              "Total number of people in image =  7\n",
              "             Timestamp Age  Gender location_category bestbuy_employee\n",
              "0  04/03/2020 19:53:25  41    Male            Isle_2               No\n",
              "1  04/03/2020 19:53:25  52  Female           cashier               No\n",
              "2  04/03/2020 19:53:25  22  Female            Isle_1               No\n",
              "3  04/03/2020 19:53:25  22  Female            Isle_1               No\n",
              "4  04/03/2020 19:53:25  32  Female          entrance               No\n",
              "5  04/03/2020 19:53:25  32  Female          entrance               No\n",
              "6  04/03/2020 19:53:25  32  Female          entrance               No\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}